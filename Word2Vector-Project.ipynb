{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "strange-freedom",
   "metadata": {},
   "source": [
    "## Importování dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distributed-tyler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19816</th>\n",
       "      <td>pan,poslanec,mikuláš,ferjenčík,faktickou,pozná...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19817</th>\n",
       "      <td>já,se,také,pokusím,vystoupit,naposledy,každopá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19818</th>\n",
       "      <td>pan,předseda,kalousek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19819</th>\n",
       "      <td>rámci,konsenzuální,diskuse,navrhuji,kompromis,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19820</th>\n",
       "      <td>tuto,chvíli,nemám,nikoho,přihlášeného,do,obecn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Line\n",
       "19816  pan,poslanec,mikuláš,ferjenčík,faktickou,pozná...\n",
       "19817  já,se,také,pokusím,vystoupit,naposledy,každopá...\n",
       "19818                              pan,předseda,kalousek\n",
       "19819  rámci,konsenzuální,diskuse,navrhuji,kompromis,...\n",
       "19820  tuto,chvíli,nemám,nikoho,přihlášeného,do,obecn..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('psp_records_list.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-maple",
   "metadata": {},
   "source": [
    "## Listy vět sestavené z jednotlivých slov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(df):\n",
    "    df_values = df.values.tolist()\n",
    "    all_sentences = []\n",
    "    for index in range(df.size):\n",
    "        all_sentences.append(df_values[index][0].split(',')) \n",
    "    return all_sentences\n",
    "\n",
    "all_sentences = get_sentences(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-sequence",
   "metadata": {},
   "source": [
    "## Lemmatizace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indoor-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplemma\n",
    "\n",
    "langdata = simplemma.load_data('cs')\n",
    "lemma = []\n",
    "for i in range(len(all_sentences)):\n",
    "    lemma.append([simplemma.lemmatize(t, langdata).lower() for t in all_sentences[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-jackson",
   "metadata": {},
   "source": [
    "## Zbavení se diakritiky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "uniform-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemma = all_sentences.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriental-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def deaccent(unistr):\n",
    "    return \"\".join(aChar \n",
    "                   for aChar in unicodedata.normalize(\"NFD\", unistr) \n",
    "                   if not unicodedata.combining(aChar))\n",
    "\n",
    "for i in range(len(lemma)):\n",
    "    for j in range(len(lemma[i])):\n",
    "        lemma[i][j] = deaccent(lemma[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-oriental",
   "metadata": {},
   "source": [
    "## Zbavení se nejfrekventovanějších slov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "undefined-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "def frequent(lst):\n",
    "    fdist = FreqDist()\n",
    "    for i in range(len(lst)):\n",
    "        for j in range(len(lst[i])):\n",
    "            fdist[lst[i][j]] += 1\n",
    "    return(fdist)\n",
    "            \n",
    "frequency_bef = frequent(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "handmade-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = []\n",
    "for i in range(21):\n",
    "    most_common.append(frequency_bef.most_common()[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "corrected-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_common_words(lst):\n",
    "    for word in most_common:\n",
    "        for index in range(len(lst)):\n",
    "            while word in lst[index]:\n",
    "                lst[index].remove(word)\n",
    "                \n",
    "remove_common_words(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "permanent-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_aft1 = frequent(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-billy",
   "metadata": {},
   "source": [
    "## Odstranění tzv. stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "honest-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_json(\"stop_words_czech.json\")\n",
    "    \n",
    "for i in range(stopwords.size):\n",
    "    word = simplemma.lemmatize(stopwords.iloc[i,0], langdata)\n",
    "    word = deaccent(word.lower())\n",
    "    if word not in most_common:\n",
    "        most_common.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "previous-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_common_words(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unusual-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_aft = frequent(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "square-sentence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of characters before removing words: 2897666 \n",
      "Number of characters after removing most_common: 2037704 \n",
      "Number of characters after removing most_common+stopwords: 1618770 \n",
      "Final difference: 1278896\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "y=0\n",
    "z=0\n",
    "\n",
    "for value in frequency_bef.values():\n",
    "    x += value\n",
    "for value in frequency_aft.values():\n",
    "    y += value\n",
    "for value in frequency_aft1.values():\n",
    "    z += value\n",
    "\n",
    "print(\"\\nNumber of characters before removing words:\",x,\n",
    "      \"\\nNumber of characters after removing most_common:\",z,\n",
    "      \"\\nNumber of characters after removing most_common+stopwords:\",y,\n",
    "      \"\\nFinal difference:\",x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-extraction",
   "metadata": {},
   "source": [
    "# Word2Vec - knihovna gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prime-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "latin-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(lemma, size=200, min_count=4, window=10, alpha=0.025, workers=10, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "affiliated-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = word2vec.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-baltimore",
   "metadata": {},
   "source": [
    "## Slovo reprezentováno jako vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sustained-function",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.51175576e-01, -2.79717555e-04, -1.82915241e-01, -3.40548217e-01,\n",
       "       -2.60031611e-01,  1.36953562e-01, -1.55284822e-01, -1.02680236e-01,\n",
       "        6.49239868e-02, -2.79741406e-01, -2.80437857e-01, -3.54300551e-02,\n",
       "        1.30780235e-01,  8.73002261e-02, -2.61862546e-01, -2.65694857e-01,\n",
       "       -1.35317042e-01, -1.14354350e-01, -2.34881222e-01,  3.78472544e-03,\n",
       "        2.45107915e-02,  3.59781235e-01,  4.16202009e-01, -1.10081986e-01,\n",
       "       -1.75781980e-01,  1.56864107e-01, -1.40179351e-01,  2.98176616e-01,\n",
       "        1.03017040e-01, -1.08725980e-01, -9.24001262e-02, -2.30912685e-01,\n",
       "        1.46904543e-01,  4.91378307e-02, -3.79550338e-01, -5.52398637e-02,\n",
       "       -5.00715196e-01,  2.60691345e-01,  9.81825814e-02, -4.20340598e-01,\n",
       "        1.84053704e-01,  5.07472344e-02, -1.56234711e-01, -3.18947703e-01,\n",
       "        3.73416208e-02, -4.18067724e-01, -5.11574864e-01,  1.25493437e-01,\n",
       "       -3.88484634e-02,  3.11053246e-01, -4.06919658e-01, -2.38618225e-01,\n",
       "        4.99025136e-01,  1.54162794e-01, -4.80827212e-01, -7.00052306e-02,\n",
       "       -5.37715614e-01, -3.57464522e-01,  4.29939866e-01, -7.63596073e-02,\n",
       "        2.43570164e-01, -4.04894352e-01,  8.11040223e-01, -2.39903525e-01,\n",
       "        7.95198828e-02, -1.69313587e-02,  2.01292917e-01,  3.61514278e-02,\n",
       "       -2.46784732e-01, -2.38691494e-01,  1.13141783e-01,  1.59871861e-01,\n",
       "        4.00948852e-01,  2.73033530e-01, -1.54704377e-01, -2.95445383e-01,\n",
       "        5.13078213e-01,  1.07048480e-02,  2.21092507e-01, -1.26633644e-01,\n",
       "        1.04560450e-01,  4.70547020e-01, -2.28379786e-01,  1.05137549e-01,\n",
       "        1.91014171e-01, -1.25635460e-01, -7.74068385e-02, -8.88728425e-02,\n",
       "        1.18147455e-01,  1.75625220e-01,  2.54254136e-02, -7.88119510e-02,\n",
       "       -4.57552642e-01, -5.08235157e-01, -2.21648127e-01,  2.58885711e-01,\n",
       "       -5.77556752e-02,  3.45235556e-01,  6.33881927e-01,  1.78523973e-01,\n",
       "        1.82510823e-01,  9.70183164e-02, -3.24702859e-01, -1.35581583e-01,\n",
       "       -5.94229698e-02, -2.83151507e-01, -2.31031597e-01, -1.93563670e-01,\n",
       "       -1.87246636e-01, -1.35235293e-02, -4.75368679e-01, -2.86317885e-01,\n",
       "       -3.25486451e-01, -2.61202365e-01,  1.60054564e-01, -1.99094951e-01,\n",
       "       -6.59449622e-02, -2.48612538e-01,  1.99474636e-02,  1.09332509e-01,\n",
       "       -1.18327431e-01, -1.73597440e-01,  1.31960493e-02, -1.09553091e-01,\n",
       "        1.64727077e-01,  3.14185381e-01,  1.63463533e-01,  5.17309785e-01,\n",
       "        1.20581975e-02, -2.09096864e-01,  1.15858749e-01,  1.30689871e-02,\n",
       "        3.20976190e-02,  8.59215856e-03, -5.09893775e-01, -3.77821922e-01,\n",
       "       -2.63880074e-01, -4.88145165e-02,  1.15158185e-01,  5.16064204e-02,\n",
       "        1.37089258e-02, -6.50133565e-02,  2.09037736e-01, -1.34043187e-01,\n",
       "       -2.41816953e-01, -1.69150472e-01, -2.57692516e-01, -3.91338080e-01,\n",
       "       -3.00031245e-01,  1.75393417e-01,  2.33989775e-01, -5.94661295e-01,\n",
       "       -1.18886836e-01,  5.01867272e-02, -6.46905839e-01, -3.98228377e-01,\n",
       "        2.59111702e-01, -1.49529085e-01, -1.97220474e-01,  3.91582809e-02,\n",
       "        4.52977084e-02, -2.86002904e-01, -9.36141685e-02, -5.97044490e-02,\n",
       "       -4.42639999e-02, -2.33577475e-01,  4.31531161e-01,  2.49556199e-01,\n",
       "        2.70580441e-01, -4.36555706e-02, -1.77102149e-01,  9.65395048e-02,\n",
       "        2.71676481e-02,  1.28368855e-01,  1.17092364e-01,  1.55498326e-01,\n",
       "       -9.54266042e-02, -1.91524446e-01,  1.35822833e-01,  1.70521036e-01,\n",
       "        5.30432016e-02,  7.20999062e-01,  3.18645000e-01,  1.61243573e-01,\n",
       "        4.33332101e-02,  4.99174111e-02,  2.47025117e-01, -1.41694814e-01,\n",
       "       -2.64858484e-01, -2.15132058e-01, -2.67793357e-01, -3.76349688e-01,\n",
       "       -2.94920970e-02,  2.31286004e-01, -2.70971298e-01, -3.10949475e-01,\n",
       "       -3.64047289e-02,  4.75696504e-01, -3.51916701e-02,  3.71626586e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv['zeman']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-malawi",
   "metadata": {},
   "source": [
    "## Nalezení n nejpodobnějších slov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sustainable-hours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Miloš\n",
      "('zeman', 0.8373407125473022)\n",
      "('general', 0.7359596490859985)\n",
      "('zemana', 0.728776752948761)\n",
      "('babis', 0.7067705392837524)\n",
      "('prezident', 0.6905307769775391)\n",
      "('andrej', 0.6855937242507935)\n",
      "('vacka', 0.6632065773010254)\n",
      "('minsk', 0.6614105701446533)\n",
      "('lukasenkovi', 0.6601101756095886)\n",
      "('eduard', 0.6591899394989014)\n"
     ]
    }
   ],
   "source": [
    "search_word = input(\"> \").lower()\n",
    "search_word = deaccent(simplemma.lemmatize(search_word, langdata))\n",
    "\n",
    "try:\n",
    "    most_similar = word2vec.wv.most_similar(search_word)\n",
    "    print(*most_similar, sep='\\n')\n",
    "except:\n",
    "    print(\"Slovo se nenachází ve slovníku.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "understanding-trade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Zeman\n",
      "('milos', 0.8373407125473022)\n",
      "('zemana', 0.714470624923706)\n",
      "('babis', 0.6769558787345886)\n",
      "('garrigue', 0.66814124584198)\n",
      "('bakala', 0.6578290462493896)\n",
      "('andrej', 0.655814528465271)\n",
      "('dr', 0.6424289345741272)\n",
      "('masaryk', 0.6303917169570923)\n",
      "('vacka', 0.6233670711517334)\n",
      "('plukovnik', 0.6230596303939819)\n"
     ]
    }
   ],
   "source": [
    "search_word = input(\"> \").lower()\n",
    "search_word = deaccent(simplemma.lemmatize(search_word, langdata))\n",
    "\n",
    "try:\n",
    "    most_similar = word2vec.wv.most_similar(search_word)\n",
    "    print(*most_similar, sep='\\n')\n",
    "except:\n",
    "    print(\"Slovo se nenachází ve slovníku.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "expected-pickup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ANO\n",
      "('trikolora', 0.6071336269378662)\n",
      "('spd', 0.4940462112426758)\n",
      "('cssd', 0.48995640873908997)\n",
      "('blm', 0.46352341771125793)\n",
      "('komunista', 0.45486903190612793)\n",
      "('ozyvat', 0.4403122365474701)\n",
      "('pravda', 0.4396103620529175)\n",
      "('lavice', 0.43255114555358887)\n",
      "('ods', 0.43176037073135376)\n",
      "('smich', 0.4316036105155945)\n"
     ]
    }
   ],
   "source": [
    "search_word = input(\"> \").lower()\n",
    "search_word = deaccent(simplemma.lemmatize(search_word, langdata))\n",
    "\n",
    "try:\n",
    "    most_similar = word2vec.wv.most_similar(search_word)\n",
    "    print(*most_similar, sep='\\n')\n",
    "except:\n",
    "    print(\"Slovo se nenachází ve slovníku.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "strong-shepherd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ODS\n",
      "('top', 0.83887779712677)\n",
      "('cssd', 0.8099815845489502)\n",
      "('kscm', 0.797346830368042)\n",
      "('lidovec', 0.7641809582710266)\n",
      "('piratu', 0.7255417108535767)\n",
      "('predkladali', 0.7247452735900879)\n",
      "('opozicni', 0.6996139883995056)\n",
      "('komunista', 0.6667767763137817)\n",
      "('obcansti', 0.662468671798706)\n",
      "('levicova', 0.6528711318969727)\n"
     ]
    }
   ],
   "source": [
    "search_word = input(\"> \").lower()\n",
    "search_word = deaccent(simplemma.lemmatize(search_word, langdata))\n",
    "\n",
    "try:\n",
    "    most_similar = word2vec.wv.most_similar(search_word)\n",
    "    print(*most_similar, sep='\\n')\n",
    "except:\n",
    "    print(\"Slovo se nenachází ve slovníku.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
