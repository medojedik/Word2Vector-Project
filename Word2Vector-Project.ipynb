{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "strange-freedom",
   "metadata": {},
   "source": [
    "## Importování dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distributed-tyler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19816</th>\n",
       "      <td>pan,poslanec,mikuláš,ferjenčík,faktickou,pozná...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19817</th>\n",
       "      <td>já,se,také,pokusím,vystoupit,naposledy,každopá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19818</th>\n",
       "      <td>pan,předseda,kalousek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19819</th>\n",
       "      <td>rámci,konsenzuální,diskuse,navrhuji,kompromis,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19820</th>\n",
       "      <td>tuto,chvíli,nemám,nikoho,přihlášeného,do,obecn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Line\n",
       "19816  pan,poslanec,mikuláš,ferjenčík,faktickou,pozná...\n",
       "19817  já,se,také,pokusím,vystoupit,naposledy,každopá...\n",
       "19818                              pan,předseda,kalousek\n",
       "19819  rámci,konsenzuální,diskuse,navrhuji,kompromis,...\n",
       "19820  tuto,chvíli,nemám,nikoho,přihlášeného,do,obecn..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('psp_records_list.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-maple",
   "metadata": {},
   "source": [
    "## Listy vět sestavené z jednotlivých slov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(df):\n",
    "    df_values = df.values.tolist()\n",
    "    all_sentences = []\n",
    "    for index in range(df.size):\n",
    "        all_sentences.append(df_values[index][0].split(',')) \n",
    "    return all_sentences\n",
    "\n",
    "all_sentences = get_sentences(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-sequence",
   "metadata": {},
   "source": [
    "## Lemmatizace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "laughing-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "import majka\n",
    "morph = majka.Majka('./majka.w-lt')\n",
    "\n",
    "morph.tags = False\n",
    "morph.first_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "renewable-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = all_sentences.copy()\n",
    "for i in range(len(lemma)):\n",
    "    for j in range(len(lemma[i])):\n",
    "        if len((morph.find(lemma[i][j].upper())))>0:\n",
    "            lemma[i][j]=morph.find(lemma[i][j].upper())[0]['lemma']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-jackson",
   "metadata": {},
   "source": [
    "## Zbavení se diakritiky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriental-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def deaccent(unistr):\n",
    "    return \"\".join(aChar \n",
    "                   for aChar in unicodedata.normalize(\"NFD\", unistr) \n",
    "                   if not unicodedata.combining(aChar))\n",
    "\n",
    "for i in range(len(lemma)):\n",
    "    for j in range(len(lemma[i])):\n",
    "        lemma[i][j] = deaccent(lemma[i][j].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-oriental",
   "metadata": {},
   "source": [
    "## Zbavení se nejfrekventovanějších slov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "undefined-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "def frequent(lst):\n",
    "    fdist = FreqDist()\n",
    "    for i in range(len(lst)):\n",
    "        for j in range(len(lst[i])):\n",
    "            fdist[lst[i][j]] += 1\n",
    "    return(fdist)\n",
    "            \n",
    "frequency_bef = frequent(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "handmade-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = []\n",
    "for i in range(20):\n",
    "    most_common.append(frequency_bef.most_common()[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "corrected-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_common_words(lst):\n",
    "    for word in most_common:\n",
    "        for index in range(len(lst)):\n",
    "            while word in lst[index]:\n",
    "                lst[index].remove(word)\n",
    "                \n",
    "remove_common_words(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "permanent-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_aft1 = frequent(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-billy",
   "metadata": {},
   "source": [
    "## Odstranění tzv. stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "honest-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_json(\"stop_words_czech.json\")\n",
    "    \n",
    "for i in range(stopwords.size):\n",
    "    s_word = stopwords.iloc[i,0]\n",
    "    if len(morph.find(s_word))>0:\n",
    "        word=deaccent(morph.find(s_word)[0]['lemma'].lower())\n",
    "    else:\n",
    "        word=deaccent(s_word.lower())\n",
    "    if word not in most_common:\n",
    "        most_common.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "previous-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_common_words(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unusual-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_aft = frequent(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "square-sentence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of characters before removing words: 2897666 \n",
      "Number of characters after removing most_common: 2141137 \n",
      "Number of characters after removing most_common+stopwords: 1666126 \n",
      "Final difference: 1231540\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "y=0\n",
    "z=0\n",
    "\n",
    "for value in frequency_bef.values():\n",
    "    x += value\n",
    "for value in frequency_aft.values():\n",
    "    y += value\n",
    "for value in frequency_aft1.values():\n",
    "    z += value\n",
    "\n",
    "print(\"\\nNumber of characters before removing words:\",x,\n",
    "      \"\\nNumber of characters after removing most_common:\",z,\n",
    "      \"\\nNumber of characters after removing most_common+stopwords:\",y,\n",
    "      \"\\nFinal difference:\",x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-extraction",
   "metadata": {},
   "source": [
    "# Word2Vec - knihovna gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prime-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "latin-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(lemma, size=200, min_count=8, window=10, alpha=0.025, workers=10, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "affiliated-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = word2vec.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-baltimore",
   "metadata": {},
   "source": [
    "## Slovo reprezentováno jako vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sustained-function",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.43386754,  0.74826026, -0.00257947, -0.06355972, -0.10731003,\n",
       "       -0.17768575, -0.5169839 , -0.12985788, -0.20703898, -0.03963907,\n",
       "       -0.20919181,  1.2892985 , -0.6796307 ,  0.46543524,  0.04570214,\n",
       "        0.45597324,  0.27578112,  0.14600573,  0.14410338,  0.10679486,\n",
       "        0.5053489 , -0.00880062,  0.1137164 , -0.08536599,  0.07035284,\n",
       "        0.87398916, -0.09384713,  0.30372128, -0.63399464, -0.07319361,\n",
       "        0.30825043,  0.25326455, -0.10992944,  0.17186844, -0.5212144 ,\n",
       "       -0.66902685,  0.4599228 ,  0.6616107 ,  0.1336313 ,  0.6063353 ,\n",
       "        0.51631314,  0.21274175,  0.04280899, -0.91724056,  0.3544108 ,\n",
       "       -0.49956453, -0.5216537 ,  0.37241638, -0.17816351, -0.51408416,\n",
       "       -0.49368367, -0.3833033 ,  0.653759  ,  0.23066974,  0.07694104,\n",
       "        0.2932137 ,  0.20498553,  0.04653297, -0.10810111, -0.13792792,\n",
       "       -0.66973644,  0.07798081, -0.4647603 , -0.16538948, -0.37987795,\n",
       "       -0.01009958, -0.69191754, -0.0076103 , -0.81763124,  1.2357416 ,\n",
       "        0.8175897 , -0.41688922, -0.0835024 ,  0.28264192, -0.1393342 ,\n",
       "        0.3004439 ,  0.34160864,  0.805108  ,  0.2141459 ,  0.3878638 ,\n",
       "        0.02809658, -0.41892892, -0.10958852,  0.11835802,  0.21991219,\n",
       "       -0.5965834 , -0.04407071,  0.38886672,  0.18445049,  0.09834702,\n",
       "       -0.3794243 ,  0.72242594, -0.18291193,  0.35372317,  0.29280365,\n",
       "       -0.2971268 ,  0.500322  ,  0.15820053,  0.6753691 ,  0.17244203,\n",
       "        0.2062981 , -0.3332546 , -0.20460814,  0.08869356, -0.5943004 ,\n",
       "       -0.45952153,  0.4142698 ,  0.10949815,  0.019017  , -0.41981176,\n",
       "        0.37881368, -0.0152436 ,  0.0209929 ,  0.45835185,  0.06318662,\n",
       "        0.11358535,  0.00201963,  0.4991507 , -0.03528005,  0.26252702,\n",
       "       -0.3356148 ,  0.34785694,  0.5746054 , -0.1374002 ,  1.0161526 ,\n",
       "        0.18896525,  0.11269443, -0.3359625 , -0.15675129,  0.28758195,\n",
       "       -0.29388615, -0.8538837 ,  0.42189026,  0.6676092 ,  0.17457537,\n",
       "        0.14004838, -0.08341202,  0.6649665 ,  0.13418545, -0.5529321 ,\n",
       "        0.16975422, -0.3861752 , -0.16290694, -0.35734847,  0.9588452 ,\n",
       "       -0.450316  , -0.00844293, -0.12874952,  0.5665469 ,  0.12140167,\n",
       "        1.0617055 ,  0.5191614 , -0.33993596,  0.21815093, -0.06253939,\n",
       "       -0.20131122,  0.39430454,  0.13357489, -0.05263592,  0.40839043,\n",
       "       -0.12687045, -0.12023744,  0.7245741 , -1.0932726 , -0.01709996,\n",
       "        0.2096799 , -0.1860554 ,  0.59356683,  0.35850593, -0.09785976,\n",
       "       -0.39014277,  0.20422868,  0.70692325,  0.4642495 ,  0.3779287 ,\n",
       "        0.16292132, -0.06604072, -0.5820661 , -0.4328706 ,  0.01453526,\n",
       "       -0.08037625, -0.19091308, -0.24053997, -0.25383317,  0.8658554 ,\n",
       "        0.7437195 , -0.48191664,  0.13642764, -0.52437717, -0.25293326,\n",
       "        0.4622252 ,  0.09856603,  0.9495325 , -0.26020202, -0.26756275,\n",
       "       -0.49357346, -0.12918298,  1.0881337 , -0.47807533, -0.2245094 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv['zeman']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-malawi",
   "metadata": {},
   "source": [
    "## Nalezení n nejpodobnějších slov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sustainable-hours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Miloš\n",
      "('zeman', 0.8559572696685791)\n",
      "('general', 0.7472396492958069)\n",
      "('vacek', 0.7243351936340332)\n",
      "('prezident', 0.7154787182807922)\n",
      "('babisovi', 0.6910240054130554)\n",
      "('zlodejna', 0.681834876537323)\n",
      "('zlodej', 0.6817171573638916)\n",
      "('tehdejsi', 0.6758270263671875)\n",
      "('soudruh', 0.6694729328155518)\n",
      "('tvrdik', 0.6689713001251221)\n"
     ]
    }
   ],
   "source": [
    "search_word = input(\"> \").upper()\n",
    "if len(morph.find(search_word))>0:\n",
    "    search_word=deaccent(morph.find(search_word)[0]['lemma'].lower())\n",
    "else:\n",
    "    search_word=deaccent(search_word.lower())\n",
    "\n",
    "try:\n",
    "    most_similar = word2vec.wv.most_similar(search_word)\n",
    "    print(*most_similar, sep='\\n')\n",
    "except:\n",
    "    print(\"Slovo se nenachází ve slovníku.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "understanding-trade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Zeman\n",
      "('milos', 0.8559572696685791)\n",
      "('general', 0.6801844835281372)\n",
      "('krecek', 0.662620484828949)\n",
      "('vacek', 0.6537578105926514)\n",
      "('lukasenka', 0.6450490951538086)\n",
      "('zlodejna', 0.6441500782966614)\n",
      "('statnost', 0.6429609060287476)\n",
      "('alexandra', 0.6413673758506775)\n",
      "('tvrdik', 0.632576584815979)\n",
      "('babisovi', 0.6288683414459229)\n"
     ]
    }
   ],
   "source": [
    "search_word = input(\"> \").upper()\n",
    "if len(morph.find(search_word))>0:\n",
    "    search_word=deaccent(morph.find(search_word)[0]['lemma'].lower())\n",
    "else:\n",
    "    search_word=deaccent(search_word.lower())\n",
    "\n",
    "try:\n",
    "    most_similar = word2vec.wv.most_similar(search_word)\n",
    "    print(*most_similar, sep='\\n')\n",
    "except:\n",
    "    print(\"Slovo se nenachází ve slovníku.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "expected-pickup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ANO\n",
      "('trikolora', 0.6527727246284485)\n",
      "('protikorupcni', 0.5108012557029724)\n",
      "('spd', 0.49982357025146484)\n",
      "('cssd', 0.49099281430244446)\n",
      "('bds', 0.4617321491241455)\n",
      "('ozyvat', 0.45251235365867615)\n",
      "('kscm', 0.43097496032714844)\n",
      "('plena', 0.4118102192878723)\n",
      "('nesroz', 0.38261961936950684)\n",
      "('komunista', 0.3783489167690277)\n"
     ]
    }
   ],
   "source": [
    "search_word = input(\"> \").upper()\n",
    "if len(morph.find(search_word))>0:\n",
    "    search_word=deaccent(morph.find(search_word)[0]['lemma'].lower())\n",
    "else:\n",
    "    search_word=deaccent(search_word.lower())\n",
    "\n",
    "try:\n",
    "    most_similar = word2vec.wv.most_similar(search_word)\n",
    "    print(*most_similar, sep='\\n')\n",
    "except:\n",
    "    print(\"Slovo se nenachází ve slovníku.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "strong-shepherd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> TOP\n",
      "('ods', 0.8299254775047302)\n",
      "('lidovec', 0.7952907085418701)\n",
      "('kscm', 0.7395617365837097)\n",
      "('pirat', 0.6912156343460083)\n",
      "('kdu', 0.6887631416320801)\n",
      "('csl', 0.6845287680625916)\n",
      "('cssd', 0.6718961000442505)\n",
      "('senatorsky', 0.6696460843086243)\n",
      "('stan', 0.654228687286377)\n",
      "('jmenem', 0.640989363193512)\n"
     ]
    }
   ],
   "source": [
    "search_word = input(\"> \").upper()\n",
    "if len(morph.find(search_word))>0:\n",
    "    search_word=deaccent(morph.find(search_word)[0]['lemma'].lower())\n",
    "else:\n",
    "    search_word=deaccent(search_word.lower())\n",
    "\n",
    "try:\n",
    "    most_similar = word2vec.wv.most_similar(search_word)\n",
    "    print(*most_similar, sep='\\n')\n",
    "except:\n",
    "    print(\"Slovo se nenachází ve slovníku.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
